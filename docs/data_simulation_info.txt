NOTES ON CLINICAL DATA SIMULATION

The simulated data used to train the classifier (available in the 'data' folder of in this repository) were generated using Anthropic's Claude Sonnet LLM.

For obvious reasons related to HIPAA regulations, data privacy, and consent, no actual medical records could be used to train the classifier used for this capstone project. The actual classifier constructed for implementation at Mayo uses actual, labeled clinical data.

I was given permission to provide the LLM with a template of the 'summary' section of actual clinical documents to use as a foundation for data generation. All information about each fictional patient was generated by the LLM, including patient name, ALL demographic information, medicines prescribed, dosages, medical history, treatment plans, etc.

Because the format of the top-level 'summary' section is exactly consistent in the Mayo Clinic records system, the LLM was able to invent patient information which was of the correct form and reflected both the positive and negative classes of records (i.e. "Received prior RT" vs. "No prior RT"). The LLM generated 1,000 records of training data in a label proportion which accurately reflected the data sent to the Radiation Oncology department. These simulated data are available to train the classifier using the 'capstone_build_classifier' script housed in this repository's 'src' folder.

The same LLM-based process was used to generate the test_data dataset, which is also available in the 'data' folder of in this repository.

It is noteworthy that the classifier which runs internally at Mayo on actual clinical records performs nearly identically (as measured by common classifier performance metrics) to the classifier trained on the simulated data. This is expected, as the LLM-generated data reflect the actual clinical data almost exactly in terms of structure, vocabulary, and content. The only major difference being, of course, that the simulated data are entirely fictional and the patients the simulated data reference do not exist.

The generation of simulated data is the only example of LLM usage in this project. These so-called "black box" models are rarely eligible to be used in actual clinical settings due to federal and state regulations, data privacy guidelines, internal legal compliance frameworks, and the general ethical praxis of Data Science, which by right would hesitate to provide PHI to a private corporation's LLM even if doing so were *not* illegal.

FOR THE AVOIDANCE OF ANY DOUBT:
- The clinical records contained in this repository are entirely fictional and were generated by an artificial intelligence system. 
- These data are not derived from, based upon, or inclusive of the content of any actual medical records, and do not contain any protected health information (PHI) from any healthcare system or provider. 
- Any resemblance to actual patient records is purely coincidental.